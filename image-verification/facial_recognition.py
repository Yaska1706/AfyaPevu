# -*- coding: utf-8 -*-
"""Facial recognition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kvLKjmfdWccUORp6c_oaYZbAjR2mRlB8

We will use the pre-trained Keras FaceNet model provided by [Hiroki Taniai](https://github.com/nyoki-mtl) in this tutorial. It was trained on [MS-Celeb-1M dataset](https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/) and expects input images to be color, to have their pixel values whitened (standardized across all three channels), and to have a square shape of 160×160 pixels.

The model can be downloaded from here:

[Keras FaceNet Pre-Trained Model (88 megabytes)](https://drive.google.com/open?id=1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn)

Download the model file and place it in your current working directory with the filename ‘facenet_keras.h5‘.
"""

from google.colab import drive
drive.mount('/content/drive')

# Import all the necessary files!
import os
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import Model

model = tf.keras.models.load_model('./facenet_keras.h5')
model.summary()

image_path = './images/path.jpg'
img1 = cv2.imread(image_path, 1)
img = img1[...,::-1]
print(img.shape)
dim = (160, 160)
# resize image
if(img.shape != (160, 160, 3)):
  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
  print(img.shape)

x_train = np.array([img])
embedding1 = model.predict(x_train)
print(embedding1)

image_path = '/images/path.jpeg'
img1 = cv2.imread(image_path, 1)
img = img1[...,::-1]
print(img.shape)
dim = (160, 160)
# resize image
if(img.shape != (160, 160, 3)):
  img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
  print(img.shape)

x_train = np.array([img])
embedding2 = model.predict_on_batch(x_train)
print(embedding2)

dist = np.linalg.norm(embedding1-embedding2)
dist

def img_to_encoding(path, model):
  img1 = cv2.imread(path, 1)
  img = img1[...,::-1]
  dim = (160, 160)
  # resize image
  if(img.shape != (160, 160, 3)):
    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
  x_train = np.array([img])
  embedding2 = model.predict_on_batch(x_train)
  return embedding2
#
database = {}
database["danielle"] = img_to_encoding("/content/drive/MyDrive/Colab Notebooks/images/path.jpg", model)
database["younes"] = img_to_encoding("/content/drive/MyDrive/Colab Notebooks/images/path.jpeg", model)


def verify(image_path, identity, database, model):
  
    encoding = img_to_encoding(image_path, model)
    dist = np.linalg.norm(encoding-database[identity])
    print(dist)
    if dist<5:
        print("It's " + str(identity) + ", welcome in!")
        door_open = True
    else:
        print("It's not " + str(identity) + ", please go away")
        door_open = False
    return dist, door_open


#Testing if the model works

verify("/content/drive/MyDrive/Colab Notebooks/images/path.jpeg", "younes", database, model)
verify("/content/drive/MyDrive/Colab Notebooks/images/path.jpg", "danielle", database, model)

def who_is_it(image_path, database, model):
  
    encoding = img_to_encoding(image_path, model)
    
    min_dist = 100
    
    # Loop over the database dictionary's names and encodings.
    for (name, db_enc) in database.items():
        
        dist = np.linalg.norm(encoding-db_enc)
        print(dist)
        if dist<min_dist:
            min_dist = dist
            identity = name

    if min_dist > 5:
        print("Not in the database.")
    else:
        print ("it's " + str(identity) + ", the distance is " + str(min_dist))
        
    return min_dist, identity


#Testing the recognition capability
who_is_it("./images/path.jpg", database, model)